


#Library Imports

#Basics
import pandas as pd
import geopandas as gpd

#Shapely
from shapely import wkt
import shapely.geometry
from shapely.geometry import Polygon, MultiPolygon
from shapely.geometry import mapping
from shapely.geometry import shape

#Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder

#Spatial Indexing
import h3


#Import Cleaned Dataset

empl_geog = gpd.read_file('data/combined_data/empl_geog.geojson')

#Reconvert geoformats (Had to remove lists/multipolygons when saving as geojson)

# WKT strings back to Shapely geometries
empl_geog['overture_building_poly'] = empl_geog['overture_building_poly'].apply(lambda x: shapely.wkt.loads(x) if isinstance(x, str) else x)
empl_geog['osm_building_poly'] = empl_geog['osm_building_poly'].apply(lambda x: shapely.wkt.loads(x) if isinstance(x, str) else x)
empl_geog['place_points'] = empl_geog['place_points'].apply(lambda x: shapely.wkt.loads(x) if isinstance(x, str) else x)

# Convert string representations of lists back to lists
empl_geog['category_list'] = empl_geog['category_list'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

empl_geog.head()








#Before incorporating any more data into my model, I want to see how well COUNTS alone can predict employment at LSOA level

#Identifying variables (feature variables vs target to predict)
features = ['num_overture_buildings', 'num_places', 'population']
target = 'total'

X = empl_geog[features]
y = empl_geog[target]

#Split into train/test - I know I need to make this spatially sensitive but we're just going with this for now
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Init/train model
model = LinearRegression()
model.fit(X_train, y_train)

#Predictions
y_pred = model.predict(X_test)

#Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")





#Before incorporating any more data into my model, I want to see how well COUNTS alone can predict employment at LSOA level

#Identifying variables (feature variables vs target to predict)
features = ['num_osm_buildings', 'num_places', 'population']
target = 'total'

X = empl_geog[features]
y = empl_geog[target]

#Split into train/test - I know I need to make this spatially sensitive but we're just going with this for now
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Init/train model
model = LinearRegression()
model.fit(X_train, y_train)

#Predictions
y_pred = model.predict(X_test)

#Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")








# Encode POI categories in data - using One-Hot encoding

#Explode category lists
empl_geog_exploded = empl_geog.explode('category_list')

#Set up encoder
encoder = OneHotEncoder(sparse_output=False)

#Encode
encoded_categories = encoder.fit_transform(empl_geog_exploded[['category_list']])
encoded_df = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out(['category_list']))

empl_geog_exploded = pd.concat([empl_geog_exploded.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)

# Reaggregate
empl_geog_exploded.drop(columns=['category_list'], inplace=True)

# Group by LSOA11CD - sum numeric only
numeric_columns = encoded_df.columns.tolist()
empl_geog_encoded = empl_geog_exploded.groupby('LSOA11CD')[numeric_columns].sum().reset_index()

empl_geog_encoded.head()





# Function to extract slightly more information about the building footprints contained in each LSOA
def extract_multipolygon_features(multipolygon, lsoa_geometry):
    if isinstance(multipolygon, MultiPolygon):
        polygons = list(multipolygon.geoms)
    elif isinstance(multipolygon, Polygon):
        polygons = [multipolygon]
    else:
        return pd.Series({
            'num_polygons': 0,
            'total_area': 0,
            'total_perimeter': 0,
            'area_ratio': 0,
            'avg_area': 0,
            'avg_perimeter': 0
        })

    num_polygons = len(polygons)
    areas = [polygon.area for polygon in polygons]
    perimeters = [polygon.length for polygon in polygons]
    total_area = sum(areas)
    total_perimeter = sum(perimeters)
    avg_area = total_area / num_polygons if num_polygons > 0 else 0
    avg_perimeter = total_perimeter / num_polygons if num_polygons > 0 else 0

    #Built-up area ratio could result in a div by zero error if there are no buildings in an LSOA so this logic has to be included here
    try:
        area_ratio = total_area / lsoa_geometry.area
    except ZeroDivisionError:
        area_ratio = 0

    return pd.Series({
        'num_polygons': num_polygons,
        'total_area': total_area,
        'area_ratio': area_ratio,
        'total_perimeter': total_perimeter,
        'avg_area': avg_area,
        'avg_perimeter': avg_perimeter
    })



#Apply function above

#Both Building Set Geometry Features
overture_geometry_features = empl_geog.apply(
    lambda row: extract_multipolygon_features(row['overture_building_poly'], row['geometry']),
    axis=1
)
osm_geometry_features = empl_geog.apply(
    lambda row: extract_multipolygon_features(row['osm_building_poly'], row['geometry']),
    axis=1
)

empl_geog_overture_features = pd.concat([empl_geog, overture_geometry_features], axis=1)
empl_geog_osm_features = pd.concat([empl_geog, osm_geometry_features], axis=1)



#Check correct application of features
empl_geog_osm_features.head()





#Combined Dataset

all_data = pd.merge(empl_geog_osm_features, empl_geog_encoded, on='LSOA11CD')

all_data.head()








# Try again with extra polygon information

#Identifying variables (feature variables vs target to predict)
features = ['num_osm_buildings', 'num_places', 'population', 'num_polygons', 'total_area', 'area_ratio', 'total_perimeter', 'avg_area', 'avg_perimeter']
target = 'total'

X = empl_geog_osm_features[features]
y = empl_geog_osm_features[target]

#Split into train/test - I know I need to make this spatially sensitive but we're just going with this for now
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Init/train model
model = LinearRegression()
model.fit(X_train, y_train)

#Predictions
y_pred = model.predict(X_test)

#Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")





# Try again with extra polygon information

#Identifying variables (feature variables vs target to predict)
features = ['num_osm_buildings', 'num_places', 'population', 'num_polygons', 'total_area', 'area_ratio', 'total_perimeter', 'avg_area', 'avg_perimeter']
target = 'total'

X = empl_geog_osm_features[features]
y = empl_geog_osm_features[target]

#Split into train/test - I know I need to make this spatially sensitive but we're just going with this for now
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Init/train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

#Predictions
y_pred = model.predict(X_test)

#Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")





# Try again with extra polygon information

#Identifying variables (feature variables vs target to predict)
features = ['num_osm_buildings', 'num_places', 'population', 'num_polygons', 'total_area', 'area_ratio', 'total_perimeter', 'avg_area', 'avg_perimeter']
target = 'total'

X = empl_geog_osm_features[features]
y = empl_geog_osm_features[target]

#Split into train/test - I know I need to make this spatially sensitive but we're just going with this for now
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Init/train model
model = GradientBoostingRegressor()
model.fit(X_train, y_train)

#Predictions
y_pred = model.predict(X_test)

#Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")





#Execute the model

features = ['num_osm_buildings', 'num_places', 'population'] + list(encoded_df.columns)
target = 'total'

# Split the dataset - 80/20 train test
X_train, X_test, y_train, y_test = train_test_split(all_data[features], all_data[target], test_size=0.2, random_state=42)

# Initialize the model - Random Forest
model = RandomForestRegressor(random_state=42)

# Train the model

model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"\nMean Squared Error: {mse}")

r_squared = r2_score(y_test, y_pred)
print(f"R-squared: {r_squared}")





features = ['num_polygons', 'total_area', 'total_perimeter', 'area_ratio', 'avg_area', 'avg_perimeter', 'num_osm_buildings', 'num_places', 'population'] + list(encoded_df.columns)
target = 'total'

# Split the dataset - 80/20 train test
X_train, X_test, y_train, y_test = train_test_split(all_data[features], all_data[target], test_size=0.2, random_state=42)

# Initialize the model - Random Forest
model = RandomForestRegressor(random_state=42)

# Train the model

model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"\nMean Squared Error: {mse}")

r_squared = r2_score(y_test, y_pred)
print(f"R-squared: {r_squared}")





features = ['num_polygons', 'total_area', 'total_perimeter', 'area_ratio', 'avg_area', 'avg_perimeter', 'num_osm_buildings', 'num_places', 'population'] + list(encoded_df.columns)
target = 'total'

# Split the dataset - 80/20 train test
X_train, X_test, y_train, y_test = train_test_split(all_data[features], all_data[target], test_size=0.2, random_state=42)

# Initialize the model - Random Forest
model = GradientBoostingRegressor()

# Train the model

model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"\nMean Squared Error: {mse}")

r_squared = r2_score(y_test, y_pred)
print(f"R-squared: {r_squared}")
